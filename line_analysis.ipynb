{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epic Chat Chain by the Numbers\n",
    "\n",
    "For this analysis, I pulled down the chat history back to February 2017. Parsed it out, and ran some stats.\n",
    "\n",
    "Inspired by: https://github.com/mskeving/email-analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, parse out the textfile data into a useable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from random import randint\n",
    "import warnings\n",
    "\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "DATE_FORMAT = '%a, %m/%d/%Y'\n",
    "TIME_FORMAT = '%I:%M %p'\n",
    "PACIFIC_TIME = pytz.timezone('US/Pacific')\n",
    "TIME_ZERO = datetime(1900, 1, 1)\n",
    "\n",
    "with open('[LINE] Chat in Epic Chat Chain.txt', 'r') as f:\n",
    "    raw_text = f.read()\n",
    "    \n",
    "days = raw_text.split('\\n\\n')\n",
    "\n",
    "columns = ['timestamp', 'name', 'text']\n",
    "records = pd.DataFrame()\n",
    "\n",
    "# days[0] is header\n",
    "\n",
    "for day in days[1:]:\n",
    "    lines = day.split('\\n')\n",
    "    first_value_line = 1\n",
    "    \n",
    "    try:\n",
    "        date = datetime.strptime(lines[0], DATE_FORMAT)\n",
    "    except ValueError:\n",
    "        # '\\n\\n' was in text, carry on same day\n",
    "        first_value_line = 0\n",
    "    \n",
    "    for line_int, line in enumerate(lines[first_value_line:]):\n",
    "    \n",
    "        try:\n",
    "            time, name, text = tuple(line.split('\\t'))\n",
    "        except ValueError:\n",
    "            # if '\\n' in text, next line should append to previous\n",
    "            records.loc[records.index.max(), 'text'] = records.loc[records.index.max(), 'text'] + ' ' + line\n",
    "\n",
    "            # trying to add milliseconds in case the new line comes in after a double line... \n",
    "            # line_int + records.loc[records.index.max(), 'timestamp'].microsecond / 1000\n",
    "\n",
    "        # adding line_int milliseconds to separate same-minute stamped records\n",
    "        delta = datetime.strptime(time, TIME_FORMAT) - TIME_ZERO + timedelta(milliseconds=line_int)\n",
    "        timestamp = PACIFIC_TIME.localize(date + delta)\n",
    "        new_df = pd.DataFrame(dict(zip(columns, [timestamp, name, text])), index=[0])\n",
    "\n",
    "        records = pd.concat([records, new_df], ignore_index=True)\n",
    "    \n",
    "records = records.set_index('timestamp')\n",
    "records['timestamp'] = records.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who's the chattiest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = records.groupby('name')['timestamp'].agg('count')  \n",
    "\n",
    "fig = plt.figure(figsize=(16, 3))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.bar(x=count.index, height=count.values, width=0.5)\n",
    "ax.set_xticklabels(labels=count.index, rotation=80, ha='right')\n",
    "\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Who's the rooster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assume day starts at 5am\n",
    "adjusted_times = records['timestamp'] + pd.Timedelta(-5, unit='h')\n",
    "first_times = adjusted_times.groupby(records.index.date).min().values + pd.Timedelta(5, unit='h')\n",
    "first_messages = records.loc[first_times]\n",
    "first_count = first_messages.groupby('name')['timestamp'].count()\n",
    "sorted_first_count = first_count.sort_values(ascending=False)\n",
    "\n",
    "ax = sorted_first_count.plot(kind='bar', rot=80, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run some text metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records['birthday'] = 0\n",
    "records['bad_words'] = 0\n",
    "records['photo'] = 0\n",
    "records['sticker'] = 0\n",
    "records['emoji'] = 0\n",
    "records['exclaimation'] = 0\n",
    "records['reconstructed_sentence'] = ''\n",
    "\n",
    "with open('badwords.txt', 'r') as f:\n",
    "    bad_words = f.readlines()\n",
    "bad_words = [word.strip().lower() for word in bad_words]\n",
    "\n",
    "names = {}\n",
    "for timestamp, row in records.iterrows():\n",
    "    name = row['name']\n",
    "    text = row['text'].lower()\n",
    "    if not name in names:\n",
    "        names[name] = {'first': {}, 'any': {}, 'end': {}}\n",
    "        \n",
    "    words = text.split(' ')\n",
    "    \n",
    "    bad_word_count = 0\n",
    "    sticker_count = 0\n",
    "    emoji_count = 0\n",
    "    photo_count = 0\n",
    "    \n",
    "    for i, word in enumerate(words):\n",
    "        if word.lower() in bad_words:\n",
    "            bad_word_count += 1   \n",
    "        elif word.startswith('(') and word.endswith(')'):\n",
    "            emoji_count += 1\n",
    "        elif word == '[sticker]':\n",
    "            sticker_count += 1\n",
    "        elif word in ['[photo]', '[video]']:\n",
    "            photo_count += 1\n",
    "            \n",
    "        # make markov map\n",
    "        if i >= 2:\n",
    "            prefix = (words[i-2], words[i-1])\n",
    "            \n",
    "            if prefix not in names[name]['any']:\n",
    "                names[name]['any'][prefix] = []\n",
    "            if word not in names[name]['any'][prefix]:\n",
    "                names[name]['any'][prefix].extend([word])\n",
    "                \n",
    "            if i == 2:\n",
    "                if prefix not in names[name]['first']:\n",
    "                    names[name]['first'][prefix] = []\n",
    "                if word not in names[name]['first'][prefix]:\n",
    "                    names[name]['first'][prefix].extend([word])\n",
    "                \n",
    "            if i == len(words)-1:\n",
    "                if prefix not in names[name]['end']:\n",
    "                    names[name]['end'][prefix] = []\n",
    "                if word not in names[name]['end'][prefix]:\n",
    "                    names[name]['end'][prefix].extend([word])\n",
    "            \n",
    "    records.set_value(timestamp, 'birthday', text.lower().count('birth')) \n",
    "    records.set_value(timestamp, 'bad_words', bad_word_count)\n",
    "    records.set_value(timestamp, 'sticker', sticker_count)\n",
    "    records.set_value(timestamp, 'emoji', emoji_count)\n",
    "    records.set_value(timestamp, 'photo', photo_count)\n",
    "    records.set_value(timestamp, 'exclaimation', text.count('!'))\n",
    "    records.set_value(timestamp, 'reconstructed_sentence', ' '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyroglyphic award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticker_count = records.groupby('name')['sticker'].agg('sum')\n",
    "\n",
    "sticker_rate = sticker_count / count\n",
    "sticker_rate = sticker_rate.sort_values(ascending=False)\n",
    "\n",
    "ax = sticker_rate.plot(kind='bar', rot=80, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoji award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticker_count = records.groupby('name')['emoji'].agg('sum')\n",
    "\n",
    "sticker_rate = sticker_count / count\n",
    "sticker_rate = sticker_rate.sort_values(ascending=False)\n",
    "\n",
    "ax = sticker_rate.plot(kind='bar', rot=80, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potty-mouth award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_only = records.copy()\n",
    "text_only = text_only[text_only['sticker'] == 0]\n",
    "text_only = text_only[text_only['photo'] == 0]\n",
    "text_count = text_only.groupby('name')['timestamp'].agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swear_count = text_only.groupby('name')['bad_words'].agg('sum')\n",
    "\n",
    "swear_rate = swear_count / text_count\n",
    "swear_rate = swear_rate.sort_values(ascending=False)\n",
    "\n",
    "ax = swear_rate.plot(kind='bar', rot=80, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text_only[text_only['name'] == 'Nathan Shayefar']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swear_rate = swear_rate.drop('Nathan Shayefar')\n",
    "\n",
    "ax = swear_rate.plot(kind='bar', rot=80, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excitement award"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclaim_count = records.groupby('name')['exclaimation'].agg('sum')\n",
    "\n",
    "exclaim_rate = exclaim_count / count\n",
    "exclaim_rate = exclaim_rate.sort_values(ascending=False)\n",
    "\n",
    "ax = exclaim_rate.plot(kind='bar', rot=80, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records['exclaim_exists'] = records['exclaimation'] > 0\n",
    "exclaim_count = records.groupby('name')['exclaim_exists'].agg('sum')\n",
    "\n",
    "exclaim_rate = exclaim_count / text_count\n",
    "exclaim_rate = exclaim_rate.sort_values(ascending=False)\n",
    "\n",
    "ax = exclaim_rate.plot(kind='bar', rot=80, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Happiest Birthday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tz_aware_bday(month, day):\n",
    "    return PACIFIC_TIME.localize(datetime(2017, month, day))\n",
    "    \n",
    "birthday_df = pd.DataFrame.from_dict({\n",
    "    datetime(2017, 2, 25): \"Peter\",\n",
    "    datetime(2017, 3, 19): \"Pat\",\n",
    "    datetime(2017, 3, 23): \"Brittany\",\n",
    "    datetime(2017, 4, 13): \"Wetenhall\",\n",
    "    datetime(2017, 4, 20): \"Dhwani\",\n",
    "    datetime(2017, 4, 25): \"Ross\",\n",
    "    datetime(2017, 5, 22): \"Jordan\",\n",
    "    datetime(2017, 6, 1): \"Rebs\",\n",
    "    datetime(2017, 6, 4): \"Joe\",\n",
    "    datetime(2017, 6, 25): \"Robpoole\",\n",
    "    datetime(2017, 7, 20): \"Theo\",\n",
    "    datetime(2017, 9, 17): \"Natalie\",\n",
    "}, orient='index').rename(columns={0: 'name'})\n",
    "\n",
    "bday_count = records.groupby(records['timestamp'].dt.date)[['birthday']].agg('sum')\n",
    "bday_count = pd.merge(bday_count, birthday_df, how='left', left_index=True, right_index=True)\n",
    "\n",
    "bday_count = bday_count.sort_values(by='birthday', ascending=False)[:5]\n",
    "bday_count = bday_count.set_index('name')\n",
    "\n",
    "ax = bday_count.plot(kind='bar', rot=0, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birthday = records[(records['birthday'] > 0) & (records.index.hour > 5)]\n",
    "first_times = birthday.groupby(birthday.index.date)['timestamp'].agg('min')\n",
    "bday_count = pd.Series(name='bday_count')\n",
    "for date, time in first_times.iteritems():\n",
    "    bday_messages = records[\n",
    "        (records['timestamp'] >= time) & \n",
    "        (records['timestamp'] < (time + pd.Timedelta(120, 'm')))\n",
    "    ]\n",
    "    bday_count[date] = bday_messages['text'].count()\n",
    "\n",
    "bday_count = birthday_df.join(bday_count)\n",
    "\n",
    "bday_count = bday_count.sort_values(by='bday_count', ascending=False)[:5]\n",
    "bday_count = bday_count.set_index('name')\n",
    "\n",
    "ax = bday_count.plot(kind='bar', rot=0, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Jordan-bday.jpg \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_count = records.groupby('name')['photo'].agg('sum')\n",
    "\n",
    "photo_rate = photo_count / count\n",
    "photo_rate = photo_rate.sort_values(ascending=False)\n",
    "\n",
    "ax = photo_rate.plot(kind='bar', rot=80, figsize=(16, 3), color='b')\n",
    "ax = ax.set_xticklabels(ax.get_xticklabels(), ha='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov sentence generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_element(l):\n",
    "    return l[randint(0, len(l)-1)]\n",
    "\n",
    "def make_markov(name):\n",
    "    for attempt in range(10):\n",
    "        sentence = []\n",
    "        first_choices = list(names[name]['first'].keys())\n",
    "        sentence = list(choose_element(first_choices))\n",
    "\n",
    "        key = (sentence[-2], sentence[-1])\n",
    "        next_choices = names[name]['first'][key]\n",
    "        sentence.append(choose_element(next_choices))\n",
    "\n",
    "        for _ in range(50):\n",
    "            # break if last key was end of sentence\n",
    "            if key in names[name]['end']:\n",
    "                break\n",
    "\n",
    "            key = (sentence[-2], sentence[-1])\n",
    "            try:\n",
    "                next_choices = names[name]['any'][key]\n",
    "            except:\n",
    "                print(sentence)\n",
    "                print(key)\n",
    "            sentence.append(choose_element(next_choices))\n",
    "\n",
    "        parsed_sentence = ' '.join(sentence)\n",
    "        if parsed_sentence not in records['reconstructed_sentence']:\n",
    "            return parsed_sentence\n",
    "    \n",
    "    return parsed_sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Jordan Schiff'\n",
    "make_markov(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Jordan.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Natalie.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Peter2.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Rebs.png \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/Sevs.png \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
